---
type: blog
title: LG AI 청소년 캠프 참가 후기
slug: "{{slug}}"
description: ""
date: '2024-05-14'
series: 'LG AI 청소년 캠프'
coverimage: ""
published: true
---

지난 11월에 목운중으로 전학을 와서 바쁘게 밀린 수행을 채우던 중, 급식시간에 줄을 서 있다가 포스터 하나가 눈에 들어왔다. 

![놀라운 발견](/images/uploads/SCR-20240731-kqxz.jpeg)

일단 보자마자 **'이건 나를 위한 캠프다'** 싶어서 사진을 찍긴 했다. 그런데 그 뒤로 고민을 하기 시작했는데, 이때 학원을 꽤 바쁘게 다니고 있었어서 섣불리 지원했다가 시간만 날리게 되는 초등학교 4학년때 삼성에서 하는 대회에서 한 경험이 반복되나 싶어서 며칠간 계속 생각을 했었다. 

근데? 아무리 생각해봐도 **미국 캠프**를 무료로 보내준다는 것이 너무 끌렸다. 사실 몇 년 전에 실리콘밸리를 간 적이 있긴 한데, 그때는 테크 쪽에 막 관심을 가지기 시작하던 때여서 제대로 경험을 못했다. 그러다가 코로나가 터지면서 인터넷으로 관련 정보를 자세히 알게 되면서 꼭 한 번 다시 가보고 싶다는 생각을 하고 있었다. 

결국 밑져야 본전이라는 생각을 하고 지원하기로 했다. 


## LG AI 청소년 캠프란?
집에 와서 열심히 찾아보기 시작했다. 

>LG AI 청소년 캠프는 LG디스커버리랩과 서울대학교가 함께 만드는
청소년 인공지능 교육과정입니다.

>서울대학교 1박 2일 캠프에 참여하여 일상생활 속 문제를 인공지능으로 해결하는 방안을 함께 탐색하고 10주간 온라인 AI 팀프로젝트를 수행하며 자기주도적으로 성장하여 미국 실리콘밸리 여름캠프에 무료로 참여할 수 있는 기회에 도전해 보세요!

라고 하는데, 좀 풀어서 써보면 LG 내 인공지능 교육기관인 [LG 디스커버리랩](https://www.lgdlab.or.kr/)이랑 서울대랑 협력해서 진행하는 인공지능을 활용해서 프로젝트를 수행하는 일종의 대회라고 볼 수 있겠다. 

진행 과정은 
 - 1차 온라인 접수로 아이디어를 소개하는 영상 제출, 100명 선발
 - 2월 서울대 캠프에서 팀 배정 및 계획
 - 5월 최종발표에서 평가를 통해 최종 12명 선발

정도. 

_항상 관련 기술만 엄청 찾아서 배우고, 실제로는 활용할 아이디어를 찾지 못하는 나의 습관(?)을 잘 고칠 수도 있겠다는 생각이 들었다. _


## 1차 접수
원래 나는 보고서를 작성할 때 아이디어를 한 번 잡는데 시간을 오래 쓰고 나서 빠르게 작성을 하는 타입인데, 이거 때문에 제출을 못할 뻔했다. 

한참을 생각하고서야 (아마 학교 갔다 와서 10시 정도까지 고민한 것 같다) `책을 읽을 때 컴퓨터 비전을 통해 텍스트를 읽어 LLM 처리를 통해 필요한 배경지식을 제공하거나, 번역을 해주는 기기`로 방향을 정해서 영상을 찍었다. 

제출 기한이 밤 12시였는데, 한 11시 40분 즈음에 다 찍어서 시간이 조금 남았다고 좋아하면서 제출을 하려고 했다. 그런데.. 글을 500자씩 2개, 1000자 정도 써야하는 칸이 있어서 미친듯이 쓰고 한 30초 전에 냈다. (아마 마지막으로 제출했을듯 ㅋㅋ)

그러고 나서 12월에 밤에 학원 끝나고 집에 돌아가는데 엄마께서 됐다고 전화하셨다. 내가 상이나 합격을 많이는 못해도 "이거 된다" 라고 생각하면 웬만해서는 되는데, 이것도 그렇게 생각하고 있었어서 엄청 놀라지는 않고 그냥 서울대 영재원도 떨어진 판에 이거라도 되서 다행이라고 생각했다. 


## 서울대 캠프 
![LG AI 청소민 캠프](/images/uploads/SCR-20240820-dos.png)

2월에 서울대에 가서 1박 2일로 캠프를 하면서 프로젝트를 함께 할 팀원들을 만나고, 아이디어를 구상했다. 아무리 해도 익숙해지지 않는 디자인 씽킹을 경험했고, 서울대 교수님들께서 주로 인공지능과 관련되어 강의를 해 주셨는데, 실제 대학교 오리엔테이션 수업 정도 되는 것 같은 퀄리티의 강의를 해 주셔서 이쪽 분야에 대해 내가 알고 있는 지식을 정리할 수 있었다. (남들이 많이 잤다)

낯에는 음식도 맛있고, 서울대 구경도 재미있었다. 

![여기까진 좋았다](/images/uploads/SCR-20240820-sod.png)

근데 숙소에 들어가자마자 ~~지옥~~ 고통을 경험했다. 그 다음날 아침까지 쓸만한 아이디어를 짜내야 하는데, 떠오르는 아이디어가 없었다. 마치 1차 지원 과정을 반복하는 것처럼, 한 새벽 3시까지 형들이랑 방에서 보고서를 계속 수정했다. 그러다가 결국은 내가 지원 과정에서 후보로 두었었던 `온라인 쇼핑몰에서 상품 이미지를 설명해주는 프로그램` 으로 정하고 보고서를 빨리 쓰고 잤다. 

다음날 교수님께 피드백을 받는 과정에서 **어떠한 특정 분야로 범위를 좁혀야 한다**는 의견을 받았다. 이때 당시에는 이미지 인식이라는 큰 틀은 유지하되, 과학 교과서 학습을 도와주는 쪽으로 (기본적인 해설 + 그림/도표 해석) 방향을 잡았었던 것 같다. 

일단 이정도 까지만 하고 집에 왔다. 


## 10주간 프로젝트 진행
프로젝트는 10주간, 매주 Zoom으로 모여서 소회의실에서 진행되었고, 총 3번의 중간발표 과정을 통해 피드백을 받고 개선을 할 수 있었다. 

### 역할 분담
팀은 LG 측에서 지원할 당시 작성한 정보를 바탕으로 균형을 맞춰서 짰다고 했다. 실제로 우리 팀은 팀으로 지원한 2명과 개인으로 지원한 2명(나)로 구성되었다. 팀 내에서 프로그래밍을 제대로 할 수 있는 사람이 나밖에 없어서 자연스럽게 프로그래머를 맡게 되었고, 나머지 3명이 팀장, 디자이너, 그리고 (보조?) 프로그래머/조력자(?)를 맡았다. 

### 아이디어 구체화
프로젝트의 방향성을 정하는 과정에서 기존 아이디어의 변이 (variant)가 많이 나왔다. 
 - 시각장애인들이 **의류**를 구매할 때 사진으로 정보를 얻기 힘들다. 
 - 마트에서 전시가 어지러운 등 쇼핑을 하기 어렵다. 
 - 도서를 시각장애인들이 읽기가 어렵다. 
 - 시각장애인들의 개인적인 추억이 담긴 사진을 설명해 주는 프로그램. 

각 팀원별로 하나의 의견을 제시한 뒤, 각 아이디어에 대해 사용할 수 있는 인공지능 모델, 데이터 등을 조사해서 발표하는 형식으로 방향을 정했다. 

결국은 기존 아이디어에 **의류**라는 세부사항을 더해서 진행하기로 결정했었다. 

### 인공지능 모델 / 데이터 수집
우리 팀의 능력이나, 주어진 시간 등을 고려했을 때, 직접 모델을 만들거나, 데이터를 구축한다는 것은 말도 안되는 일이어서 정말 열심히 자료조사를 했다. 한 2주 동안은 [공공데이터포털](https://data.go.kr)이랑 [Kaggle](https://kaggle.com), [Hugging Face](https://huggingface.co) 그리고 GitHub을 샅샅이 뒤졌던 것 같다. 

이 과정에서 **무언가를 실제로 실행한다는 것은 정말 어려운 일**이라는 것을 배우게 되었다. 학교에서 실습을 하거나, 예제를 돌려볼 때는 정말 쉬워 보였던 데이터 마련과 학습이 실제로 진행하다 보니 데이터 크기가 너무 크거나 (+400GB) 라이브러리 설치 과정에서 무언가 꼬이는 등 문제가 많았다. 

결국 범위를 줄인 결과인 의류도 우리에게는 너무 힘들다는 결론에 도달해서 신발로 더 범위를 줄였다. 

그리고 나서 내 맥북 프로로 YOLOv8을 훈련시켰다. 애플 실리콘 칩을 제대로 활용하는 MPS 모드(?)로 설정하고 진행했더니 생각했던 것보다 훨씬 빠르긴 했는데, 그래도 컴퓨터 사고 처음으로 비행기 이륙 소리를 들을 수 있었다. 

### 프로토타입 제작
일단 YOLO 모델은 신발의 종류 (구두, 운동화 등)와 끈 유무만 JSON 형식으로 반환하도록 학습시켰다. 

원래는 시각장애인이 주요 유저가 될 것으로 생각하고 정한 아이디어이기에, 실제로 화면이 보이지 않아도 VoiceOver 등의 기술을 통해 작동이 가능한 방식을 채택해야 했지만, 일단 우리는 이미지를 우클릭 하면 뜨는 컨텍스트 메뉴를 통해 실행 가능하도록 결정했다. 

또한, 프로젝트를 진행하다 아이디어가 순식간에 바뀌는 경험을 해보고서 깨달았다. **최대한 익숙한 기술 스택으로, 가장 단순하게 구현**해야 되겠다고. 그래서 일단 2번째 중간발표 때는 FastAPI로 백엔드를, 그리고 프론트엔드는 동일 서버에서 HTML 파일 하나로 구현을 했다. 백엔드는 단지 사용자가 요청한 이미지를 받아서 모델에 전달하는 역할만 했다. ~~생각해보니 꽤 단순하다..~~

그 뒤로는 이 정보를 OpenAI GPT-4 Turbo에 전달해 형태에 대한 더 정확한 정보를 얻을 수 있게 했다. 

## 수료식 -- 최종발표

## 후기




# 아직 작성중인 글 입니다

